# 2024_NGPI Survey Answers

## 1. Basic Metadata
- Title: Towards Efficient Neurally-Guided Program Induction for ARC-AGI
- Authors: Simon Ouellette
- Year: 2024
- Venue: arXiv (arXiv:2411.17708v1)

## 2. One-Sentence Contribution Summary
In one sentence: The paper evaluates neurally-guided program induction for ARC-AGI by comparing learning-the-grid-space and learning-the-program-space approaches, then proposing a learning-the-transformation-space variant with preliminary experiments to address out-of-distribution generalization.

## 3. Tasks Evaluated
Common domain evidence (applies to all tasks below):
> "A first full decoding loop is executed on the Vision-Language Model (VLM) that is fed one input and output grid pair from a given task’s demonstration set." (Section: Learning the Program Space)
> "The DSL revolves around the concept of a Grid, which is a custom class that contains the following information about a grid:" (Section: Appendix - Description of the DSL)
> "A utility method that converts from the pixels list to a 2D grid representation (a tuple of tuples where each value is the color at that position)." (Section: Appendix - Description of the DSL)

Hand-crafted OOD task set evidence:
> "10 new tasks are hand-crafted, specifically selected to guarantee that there is no structurally similar task ever generated in the training data." (Section: Generalization of LTS)

### Task: ARC-AGI evaluation set (full)
- Task type: Other (program induction / grid transformation)
- Dataset(s): ARC-AGI evaluation set
- Domain: Abstract grid puzzles (ARC-AGI grids)
- Evidence:
> "Table 1 reports the success rate (as a percentage of solved tasks) of various approaches on the ARC-AGI evaluation set." (Section: Performance Comparison on ARC-AGI Eval Set)

### Task: ARC-AGI evaluation set (29-task solvable subset)
- Task type: Other (program induction / grid transformation)
- Dataset(s): ARC-AGI evaluation set (subset of 29 solvable tasks)
- Domain: Abstract grid puzzles (ARC-AGI grids)
- Evidence:
> "Table 1: Success rate on full ARC-AGI evaluation set at 15-minute budget, on subset of 29 solvable tasks at 15-minute budget, and on subset of 29 solvable tasks at 5-minute budget." (Section: Performance Comparison on ARC-AGI Eval Set)

### Task: ARC-AGI hidden test set
- Task type: Other (program induction / grid transformation)
- Dataset(s): ARC-AGI hidden test set
- Domain: Abstract grid puzzles (ARC-AGI grids)
- Evidence:
> "Table 2: Success rates of different DSL versions on full ARC-AGI evaluation set at 5-minute budget, and on the 29-task DSL version 1 subset at 5-minute time budget. ARC-AGI hidden test set performance is also presented." (Section: Experiments & Results)

### Task: Task #48131b3c (ARC-AGI evaluation set; OOD test)
- Task type: Other (program induction / grid transformation)
- Dataset(s): ARC-AGI evaluation set (single task used in OOD experiment)
- Domain: Abstract grid puzzles (ARC-AGI grids)
- Evidence:
> "Task #48131b3c from ARC-AGI evaluation set: tile the original grid 2x2, and invert the colors." (Section: Generalization of LTS)

### Task: Hand-crafted task 1
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 1: gravitate the pixels to the left, then gravitate the pixels upward, then change the foreground pixels’ color to aquamarine." (Section: Generalization of LTS)

### Task: Hand-crafted task 2
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 2: rotate the grid 90 degrees, upscale it horizontally by two, and then upscale it vertically by two." (Section: Generalization of LTS)

### Task: Hand-crafted task 3
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 3: same as task 2, but add an extra operation of horizontal mirroring at the end." (Section: Generalization of LTS)

### Task: Hand-crafted task 4
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 4: same as task 3, but add an extra operation of color inversion at the end." (Section: Generalization of LTS)

### Task: Hand-crafted task 5
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 5: tile the original grid 2x4 while alternating 180-degree rotation with the identity transform on each tile." (Section: Generalization of LTS)

### Task: Hand-crafted task 6
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 6: tile the smallest object in the grid twice horizontally (i.e. concatenate it with itself horizontally), and use that as output grid." (Section: Generalization of LTS)

### Task: Hand-crafted task 7
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 7: crop the the object that contains the largest number of sub-objects, rotate it 90 degrees, and then duplicate the top row and the bottom row." (Section: Generalization of LTS)

### Task: Hand-crafted task 8
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 8: filter out the largest object in the grid and then rotate the grid 270 degrees." (Section: Generalization of LTS)

### Task: Hand-crafted task 9
- Task type: Other (program induction / grid transformation)
- Dataset(s): Hand-crafted OOD task
- Domain: Abstract grid puzzles (grid transformations)
- Evidence:
> "Hand-crafted task 9: crop the largest object in the grid, split it in half horiziontally, and merge the left and right halves with cellwise OR logic." (Section: Generalization of LTS)

## 4. Domain and Modality Scope
- Evaluation domain scope: Single domain (ARC-AGI grid tasks).
  Evidence:
  > "ARC-AGI is one of the foremost problem domains that specifically challenges this closed-world assumption." (Section: Introduction)
  > "Table 1 reports the success rate (as a percentage of solved tasks) of various approaches on the ARC-AGI evaluation set." (Section: Performance Comparison on ARC-AGI Eval Set)
- Multiple domains within the same modality: Not specified in the paper.
- Multiple modalities: Not specified in the paper (all evidence points to grid input/output pairs).
- Domain generalization or cross-domain transfer: Not claimed; the paper frames generalization as out-of-distribution within ARC-AGI task structure.
  Evidence:
  > "the test set must be out-of-distribution with respect to the training set in terms of the compositional structures of P." (Section: The Problem)

## 5. Model Sharing Across Tasks
Evidence Notes:
A. "This is done by training three separate VLM instances, one on each of the three DSLs and their associated training data generators." (Section: Experiments & Results)
B. "A first full decoding loop is executed on the Vision-Language Model (VLM) that is fed one input and output grid pair from a given task’s demonstration set." (Section: Learning the Program Space)
C. "the DSL version 2 and DSL version 3 models were separately fine-tuned on their respective datasets, starting from the pre-trained DSL version 1 model." (Section: Training Data Generation)

| Task | Shared Weights? | Fine-Tuned? | Separate Head? | Evidence |
| --- | --- | --- | --- | --- |
| ARC-AGI evaluation set (full) | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| ARC-AGI evaluation set (29-task subset) | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| ARC-AGI hidden test set | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Task #48131b3c | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 1 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 2 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 3 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 4 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 5 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 6 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 7 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 8 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |
| Hand-crafted task 9 | Yes (shared per DSL VLM) | Not specified per task (DSL-level fine-tuning only) | Not specified in the paper | A,B,C |

## 6. Input and Representation Constraints
- Fixed or variable input resolution: Not specified in the paper.
- Fixed patch size: Not specified in the paper.
- Fixed number of tokens: Not specified for inputs.
- Fixed dimensionality (e.g., strictly 2D): Yes, grid representation is explicitly 2D.
  Evidence:
  > "A utility method that converts from the pixels list to a 2D grid representation (a tuple of tuples where each value is the color at that position)." (Section: Appendix - Description of the DSL)
- Any padding or resizing requirements: Not specified in the paper.

## 7. Context Window and Attention Structure
- Maximum sequence length: 40 tokens (program decoding length).
  Evidence:
  > "The full decoding loop stops until either the maximum sequence length (40, in our experiments) is reached, or a token is found where the only class that has a probability greater than some threshold τ is the End Of Sentence class." (Section: Learning the Program Space)
- Fixed or variable sequence length: Variable (stops early at End Of Sentence or hits max length).
  Evidence:
  > "The full decoding loop stops until either the maximum sequence length (40, in our experiments) is reached, or a token is found where the only class that has a probability greater than some threshold τ is the End Of Sentence class." (Section: Learning the Program Space)
- Attention type (global/windowed/hierarchical/sparse): Not specified in the paper.
  Evidence:
  > "Specifically, the model used for the experiments has 452 million parameters, and only one decoder layer with an embedding dimensionality of 512 and 4 attention heads." (Section: VLM Architecture & Training)
- Mechanisms to manage computational cost (windowing/pooling/token pruning): Not specified for attention; only the max sequence length constraint is explicitly stated (see above).

## 8. Positional Encoding (Critical Section)
- Positional encoding mechanism: Not specified in the paper.
- Where applied: Not specified in the paper.
- Fixed vs modified per task vs ablated/compared: Not specified in the paper.
- Evidence of mention (without mechanism details):
  > "As a result, it tends to lazily rely on positional encoding and pre-determined sequence templates that it learned during training." (Section: Discussion)

## 9. Positional Encoding as a Variable
- Core research variable or fixed architectural assumption: Not specified in the paper.
- Multiple positional encodings compared: Not specified in the paper.
- Claims that PE choice is “not critical” or secondary: Not specified in the paper.
- Evidence of mention (no comparison reported):
  > "As a result, it tends to lazily rely on positional encoding and pre-determined sequence templates that it learned during training." (Section: Discussion)

## 10. Evidence of Constraint Masking
- Model size(s):
  Evidence:
  > "Specifically, the model used for the experiments has 452 million parameters, and only one decoder layer with an embedding dimensionality of 512 and 4 attention heads." (Section: VLM Architecture & Training)
- Dataset size(s):
  Evidence:
  > "For DSL version 1, a total of around 5M training samples (i.e., input-output grid pairs + ground-truth program sequence for distinct tasks) were generated. For DSL version 2, around 600K training samples were generated, and around 300K for DSL version 3 (because data generation is slower)." (Section: Training Data Generation)
- Scaling model size: Not explicitly tied to ARC-AGI performance; the paper notes higher parameter count and better validation accuracy vs T5/LongT5.
  Evidence:
  > "In our experiments this architecture converged faster and to a higher validation accuracy on our dataset than a T5 or LongT5 architecture, while allowing us to use a higher parameter count for the same amount of VRAM." (Section: VLM Architecture & Training)
- Scaling data / primitives and task generators (performance gains):
  Evidence:
  > "the overall performance on the ARC-AGI evaluation set increases as we add primitives and corresponding training tasks." (Section: Scaling the DSL)
- Search vs model-only performance (performance attributed to search):
  Evidence:
  > "searching over the probability space significantly extends the neural network’s reach beyond its training distribution." (Section: Discussion)

## 11. Architectural Workarounds
- Conditional independence / flat sequence to increase efficiency:
  Evidence:
  > "While typical program induction operates on a tree, GridCoder operates on a flat sequence of nodes." (Section: Conditional Independence)
  > "we choose to make a simplifying assumption of conditional independence between nodes, much like in Bayesian networks." (Section: Conditional Independence)
  > "overall we believe it yields a significant gain in efficiency: making this assumption means that we only need to call the neural network a few times while bootstrapping the probabilities." (Section: Conditional Independence)
- Probability thresholding to cap search space:
  Evidence:
  > "If we calculate that the total set of possible programs is greater than a pre-determined number, we gradually increase τ until the cut-off level results in a manageable number of programs." (Section: The Search Algorithm)
- Max sequence length for decoding (limits search depth):
  Evidence:
  > "The full decoding loop stops until either the maximum sequence length (40, in our experiments) is reached." (Section: Learning the Program Space)
- LGS grid-to-grid transformation assumption (restrictive DSL to simplify search):
  Evidence:
  > "Note that this approach assumes that all (or most) steps in program execution result in a grid-to-grid transformation." (Section: Learning the Grid Space)
  > "This is why the experiments on LGS use a DSL that strictly contains grid-to-grid transformations (DSL Version 1)." (Section: Learning the Grid Space)
- Encoder max pooling for grid embedding:
  Evidence:
  > "The experiments reported here used a Transformer encoder-only model with max pooling that outputs a flattened vector: a grid embedding." (Section: Learning the Grid Space)
- Bootstrapping multiple decoding iterations:
  Evidence:
  > "Bootstrapping in this context means that we collect the probability distributions as a mean of K decoding iterations (where K is six in our experiments)." (Section: Conditional Independence)

## 12. Explicit Limitations and Non-Claims
- Not yet competitive / proof-of-concept status:
  Evidence:
  > "The current implementations of the proposed approaches are not yet mature enough to yield an interesting or competitive performance on ARC-AGI." (Section: Introduction)
- LTS not implemented due to time; future work:
  Evidence:
  > "The third one (LTS) has not been implemented yet, due to lack of time, but it is described in a brief, general way." (Section: Introduction)
  > "While preliminary experiments are made to support this hypothesis, full implementation and experimentation is left to future work." (Section: Introduction)
- Limited DSL is main limitation:
  Evidence:
  > "Very limited work has been done on improving the DSL. This is, therefore, the main limitation of this work." (Section: Limitations and Future work)
- Need to complete DSL; not trivial:
  Evidence:
  > "Scaling the algorithms presented here to a competitive level will certainly involve completing the DSL by introducing all of the necessary primitives required to solve all ARC training and evaluation tasks. This is not as simple as going through the existing tasks and implementing primitives for every high-level functionality seen." (Section: Limitations and Future work)
- Not confident LPS alone solves ARC-AGI:
  Evidence:
  > "we are not confident that the LPS approach could solve ARC-AGI in any true sense." (Section: Conclusion)
- Data/time constraints noted:
  Evidence:
  > "More data would have been preferable, but time was a significant constraint." (Section: Training Data Generation)
