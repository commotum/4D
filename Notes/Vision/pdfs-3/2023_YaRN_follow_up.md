Number of distinct tasks evaluated: 6 (long sequence language modeling/perplexity on GovReport and Proof-pile; passkey retrieval; ARC-Challenge; HellaSwag; MMLU; TruthfulQA). (/home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:474, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:475, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:476, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:530, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:531, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:540, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:541, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:542)

Number of trained model instances required to cover all tasks: 1 (the paper fine-tunes Llama 2 models with YaRN and evaluates those fine-tuned models across perplexity, passkey retrieval, and benchmark tasks; no task-specific heads or separate training per task are described). (/home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:441, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:442, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:445, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:446, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:468, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:469, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:470, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:471, /home/jake/Developer/4D/Notes/Vision/pdfs-3/2023_YaRN.pdf:472)

$$
\boxed{
\frac{6\ \text{tasks}}{1\ \text{model}} = 6
}
$$
