# Short Identifier Examples

The following table contains examples of short identifiers. A short identifier should be **unique, stable, and easy to scan**, using the pattern **`YYYY_Key`**, where `YYYY` is the paper’s primary year and `Key` is a short, widely recognized name or abbreviation (e.g., *ViT*, *DETR*, *CLIP*). Prefer **community-standard names**, keep the key concise, avoid spaces or punctuation, and add a small suffix only if needed to disambiguate similar papers.


| Short Identifier    | Full Title                                                                                 |
| ------------------- | ------------------------------------------------------------------------------------------ |
| 2020_DeformableDETR | Deformable DETR: Deformable Transformers for End-to-End Object Detection                   |
| 2020_iGPT           | Generative Pretraining from Pixels                                                         |
| 2021_ALIGN          | Scaling Up Vision-Language Learning With Noisy Text Supervision                            |
| 2021_CoAtNet        | CoAtNet: Marrying Convolution and Attention for All Data Sizes                             |
| 2021_CvT            | CvT: Introducing Convolutions to Vision Transformers                                       |
| 2021_PVT            | Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions |
| 2021_SwinV2         | Swin Transformer V2: Scaling Up Capacity and Resolution                                    |
| 2021_Twins          | Twins: Revisiting the Design of Spatial Attention in Vision Transformers                   |
| 2022_Flamingo       | Flamingo: a Visual Language Model for Few-Shot Learning                                    |
| 2020_DeiT           | Training Data-Efficient Image Transformers & Distillation through Attention                |
| 2020_Taming         | Taming Transformers for High-Resolution Image Synthesis                                    |
| 2021_BEiT           | BEiT: BERT Pre-Training of Image Transformers                                              |
| 2021_CrossViT       | CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification          |
| 2021_DALLE          | Zero-Shot Text-to-Image Generation                                                         |
| 2021_SegFormer      | SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers         |
| 2021_TimeSformer    | Is Space-Time Attention All You Need for Video Understanding?                              |
| 2022_BEiT3          | Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks         |
| 2022_MaxViT         | MaxViT: Multi-Axis Vision Transformer                                                      |
| 2020_DETR           | End-to-End Object Detection with Transformers                                              |
| 2020_ViT            | An Image is Worth 16×16 Words: Transformers for Image Recognition at Scale                 |
| 2021_CLIP           | Learning Transferable Visual Models From Natural Language Supervision                      |
| 2021_CSWin          | CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows         |
| 2021_MAE            | Masked Autoencoders Are Scalable Vision Learners                                           |
| 2021_Swin           | Swin Transformer: Hierarchical Vision Transformer using Shifted Windows                    |
| 2021_TNT            | Transformer in Transformer                                                                 |
| 2022_BLIP           | BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding  |
| 2023_SAM            | Segment Anything                                                                           |
