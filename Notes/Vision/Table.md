| Published                | Title                                                                                                      | Lead Author         | PDF URL                                                                                                                                                         | Citations (given) | Citations (verified) | Relevance (systematic) |
| ------------------------ | ---------------------------------------------------------------------------------------------------------- | ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- | -------------------- | ---------------------- |
| 2000                     | Feedforward and Recurrent Processing in Vision                                                             | Lamme               | `https://pubmed.ncbi.nlm.nih.gov/10925037/`                                                                                                                     | 3,095             | 3,095.               | 4.70                   |
| 2007                     | Core Knowledge                                                                                             | Spelke              | `https://projects.iq.harvard.edu/files/lds/files/core_knowledge.pdf`                                                                                            | 2,409             | 1,407.               | 5.06                   |
| 2012                     | Canonical Microcircuits for Predictive Coding                                                              | Friston             | `https://pubmed.ncbi.nlm.nih.gov/23238495/`                                                                                                                     | 2,865             | 2,865.               | 6.06                   |
| 2014                     | Hierarchy of Intrinsic Timescales in Cortex                                                                | Murray              | `https://www.cns.nyu.edu/wanglab/papers/Murray_NatNeuro_2014.pdf`                                                                                               | 1,088             | 1,088.               | 5.73                   |
| 2014-10                  | Neural Turing Machines                                                                                     | Graves              | `https://arxiv.org/pdf/1410.5401.pdf`                                                                                                                           | 3,477             | 2,435.               | 6.24                   |
| 2016-03                  | Adaptive Computation Time                                                                                  | Graves              | `https://arxiv.org/pdf/1603.08983.pdf`                                                                                                                          | 614               | 614.                 | 5.74                   |
| 2017-06                  | Attention Is All You Need                                                                                  | Vaswani             | `https://arxiv.org/pdf/1706.03762.pdf`                                                                                                                          | 145,000           | 158,650.             | 8.36                   |
| 2018                     | Recurrent Relational Networks                                                                              | Palm                | `https://proceedings.neurips.cc/paper_files/paper/2018/file/e2a2dcc36a08a345332c751b2f2e476c-Paper.pdf`                                                         | 255               | 153.                 | 5.21                   |
| 2018-07                  | Universal Transformers                                                                                     | Dehghani            | `https://arxiv.org/pdf/1807.03819.pdf`                                                                                                                          | 1,226             | 821.                 | 6.01                   |
| 2018-09                  | Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset                                         | Sharma              | `https://arxiv.org/pdf/1803.10137.pdf`                                                                                                                          | 2,200             | 2,761.               | 6.98                   |
| 2018-10                  | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding                           | Devlin              | `https://arxiv.org/pdf/1810.04805.pdf`                                                                                                                          | 110,000           | 107,108.             | 8.56                   |
| 2019-08                  | LXMERT: Learning Cross-Modality Encoder Representations                                                    | Tan                 | `https://arxiv.org/pdf/1908.07490.pdf`                                                                                                                          | 5,000             | 2,730.               | 6.83                   |
| 2019-08                  | ViLBERT: Pretraining Task-Agnostic V-L Representations                                                     | Lu                  | `https://arxiv.org/pdf/1908.02265.pdf`                                                                                                                          | 4,200             | 4,132.               | 7.15                   |
| 2019-08                  | VisualBERT: A Simple and Performant Baseline for Vision and Language                                       | Li                  | `https://arxiv.org/pdf/1908.03557.pdf`                                                                                                                          | 2,200             | 2,184.               | 6.70                   |
| 2019-09                  | Deep Equilibrium Models                                                                                    | Bai                 | `https://arxiv.org/pdf/1909.01377.pdf`                                                                                                                          | 971               | 759.                 | 6.11                   |
| 2019-10                  | VideoBERT: A Joint Model for Video and Language Representation Learning                                    | Sun                 | `https://arxiv.org/pdf/1904.01766.pdf`                                                                                                                          | 1,900             | 1,343.               | 6.28                   |
| 2019-11                  | HowTo100M: Learning a Text-Video Embedding by Watching Narrated Videos                                     | Miech               | `https://arxiv.org/pdf/1906.03327.pdf`                                                                                                                          | 3,600             | 1,352.               | 6.29                   |
| 2019-11                  | On the Measure of Intelligence                                                                             | Chollet             | `https://arxiv.org/pdf/1911.01547.pdf`                                                                                                                          | 1,148             | 1,148.               | 6.35                   |
| 2020-02                  | UNITER: Universal Image-Text Representation Learning                                                       | Chen                | `https://arxiv.org/pdf/1909.11740.pdf`                                                                                                                          | 5,100             | 2,441.               | 6.72                   |
| 2020-04                  | OSCAR: Object-Semantics Aligned Pre-training for Vision-Language Tasks                                     | Li                  | `https://arxiv.org/pdf/2004.06165.pdf`                                                                                                                          | 4,100             | 2,064.               | 6.56                   |
| 2020-05                  | End-to-End Object Detection with Transformers (DETR)                                                       | Carion              | `https://arxiv.org/pdf/2005.12872.pdf`                                                                                                                          | 22,000            | 16,058.              | 7.96                   |
| 2020-10                  | An Image is Worth 16×16 Words: Vision Transformer (ViT)                                                    | Dosovitskiy         | `https://arxiv.org/pdf/2010.11929.pdf`                                                                                                                          | 80,000            | 54,212.              | 8.40                   |
| 2021-02                  | Is Space-Time Attention All You Need for Video Understanding? (TimeSformer)                                | Bertasius           | `https://arxiv.org/pdf/2102.05095.pdf`                                                                                                                          | 3,400             | 2,586.               | 6.74                   |
| 2021-02                  | Scaling Up Vision-Language Learning With Noisy Text Supervision (ALIGN)                                    | Jia                 | `https://arxiv.org/pdf/2102.05918.pdf`                                                                                                                          | 5,600             | 4,744.               | 7.07                   |
| 2021-02                  | Learning Transferable Visual Models From Natural Language Supervision (CLIP)                               | Radford             | `https://arxiv.org/pdf/2103.00020.pdf`                                                                                                                          | 50,000            | 40,257.              | 8.13                   |
| 2021-03                  | Swin Transformer                                                                                           | Liu                 | `https://arxiv.org/pdf/2103.14030.pdf`                                                                                                                          | 39,000            | 27,827.              | 8.00                   |
| 2021-04                  | RoFormer: Enhanced Transformer with Rotary Position Embedding (RoPE)                                       | Su                  | `https://arxiv.org/pdf/2104.09864.pdf`                                                                                                                          | 4,369             | 3,779.               | 6.85                   |
| 2021-06                  | VATT: Transformers for Multimodal Self-Supervised Learning                                                 | Akbari              | `https://arxiv.org/pdf/2104.11178.pdf`                                                                                                                          | 1,500             | 670.                 | 5.96                   |
| 2021-06                  | ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision                            | Kim                 | `https://arxiv.org/pdf/2102.03334.pdf`                                                                                                                          | 3,000             | 2,080.               | 6.45                   |
| 2021-06                  | VideoCLIP: Contrastive Pretraining for Zero-Shot Video-Text Understanding                                  | Xu                  | `https://arxiv.org/pdf/2109.14084.pdf`                                                                                                                          | 775               | 679.                 | 5.97                   |
| 2021-07                  | ALBEF: Align Before Fuse                                                                                   | Li                  | `https://arxiv.org/pdf/2107.07651.pdf`                                                                                                                          | 3,200             | 2,404.               | 6.52                   |
| 2021-08                  | Train Short, Test Long: Attention with Linear Biases (ALiBi)                                               | Press               | `https://arxiv.org/pdf/2108.12409.pdf`                                                                                                                          | 1,076             | 3,059.               | 6.59                   |
| 2021-11                  | LAION-400M: Open Dataset for CLIP Training                                                                 | Schuhmann           | `https://arxiv.org/pdf/2111.02114.pdf`                                                                                                                          | 1,854             | 1,691.               | 6.20                   |
| 2021-11                  | Masked Autoencoders Are Scalable Vision Learners (MAE)                                                     | He                  | `https://arxiv.org/pdf/2111.06377.pdf`                                                                                                                          | 13,000            | 9,826.               | 7.46                   |
| 2022-01                  | BLIP: Bootstrapping Language-Image Pre-training                                                            | Li                  | `https://arxiv.org/pdf/2201.12086.pdf`                                                                                                                          | 7,400             | 5,622.               | 7.14                   |
| 2022-03                  | CoCa: Contrastive Captioners                                                                               | Yu                  | `https://arxiv.org/pdf/2205.01917.pdf`                                                                                                                          | 1,600             | 1,583.               | 6.28                   |
| 2022-04                  | Flamingo: a Visual Language Model for Few-Shot Learning                                                    | Alayrac             | `https://arxiv.org/pdf/2204.14198.pdf`                                                                                                                          | 6,500             | 4,711.               | 6.97                   |
| 2022-06                  | Winoground: Probing Vision-Language Models for Compositionality                                            | Thrush              | `https://arxiv.org/pdf/2204.03162.pdf`                                                                                                                          | 1,100             | 510.                 | 5.90                   |
| 2022-12                  | LAION-5B: An Open Large-Scale Dataset for Training Next Generation Image-Text Models                       | Schuhmann           | `https://arxiv.org/pdf/2210.08402.pdf`                                                                                                                          | 1,200             | 4,414.               | 6.88                   |
| 2022-10                  | ScienceQA: Benchmark for Multimodal Reasoning                                                              | Lu                  | `https://arxiv.org/pdf/2209.09513.pdf`                                                                                                                          | 2,100             | 1,785.               | 6.38                   |
| 2023-01                  | BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Models                                       | Li                  | `https://arxiv.org/pdf/2301.12597.pdf`                                                                                                                          | 3,800             | 6,465.               | 7.18                   |
| 2023-03                  | GPT-4 Technical Report                                                                                     | OpenAI              | `https://arxiv.org/pdf/2303.08774.pdf`                                                                                                                          | 9,000             | 20,107.              | 7.73                   |
| 2023-03                  | Kosmos-1: Language Is Not All You Need                                                                     | Huang               | `https://arxiv.org/pdf/2302.14045.pdf`                                                                                                                          | 1,500             | 659.                 | 5.89                   |
| 2023-03                  | PaLM-E: An Embodied Multimodal Language Model                                                              | Driess              | `https://arxiv.org/pdf/2303.03378.pdf`                                                                                                                          | 1,600             | 2,161.               | 6.48                   |
| 2023-04                  | LLaVA: Large Language-and-Vision Assistant                                                                 | Liu                 | `https://arxiv.org/pdf/2304.08485.pdf`                                                                                                                          | 6,200             | 7,227.               | 7.29                   |
| 2023-04                  | MiniGPT-4                                                                                                  | Zhu                 | `https://arxiv.org/pdf/2304.10592.pdf`                                                                                                                          | 2,800             | 2,650.               | 6.54                   |
| 2023-05                  | ConceptARC                                                                                                 | Moskvichev          | `https://arxiv.org/pdf/2305.07141.pdf`                                                                                                                          | 130               | 130.                 | 4.90                   |
| 2023-06                  | MMBench: Evaluating Multimodal LLMs                                                                        | Liu                 | `https://arxiv.org/pdf/2307.06281.pdf`                                                                                                                          | 1,500             | 1,574.               | 6.12                   |
| 2023-07 (ACL)            | A Length-Extrapolatable Transformer (XPOS / LeX)                                                           | Sun                 | `https://aclanthology.org/2023.acl-long.816.pdf`                                                                                                                | 207               | 151.                 | 5.12                   |
| 2023-09                  | YaRN: Efficient Context Window Extension of Large Language Models                                          | Peng                | `https://arxiv.org/pdf/2309.00071.pdf`                                                                                                                          | 620               | 363.                 | 5.55                   |
| 2023-10                  | MMMU: A Massive Multidiscipline Multimodal Benchmark                                                       | Yue                 | `https://arxiv.org/pdf/2311.16502.pdf`                                                                                                                          | 900               | 1,541.               | 6.11                   |
| 2023-12                  | Gemini: A Family of Highly Capable Multimodal Models                                                       | Google              | `https://arxiv.org/pdf/2312.11805.pdf`                                                                                                                          | 3,000             | 6,810.               | 6.78                   |
| 2023-12                  | Uni3DL: Unified Model for 3D and Language Understanding                                                    | Li                  | `https://arxiv.org/pdf/2312.03026.pdf`                                                                                                                          | 11                | 7.                   | 3.93                   |
| 2024                     | Evolutionary Test-Time Compute (write-up)                                                                  | Berman              | `https://jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi`                                                                                         | 0                 | 0.                   | 3.05                   |
| 2024-01                  | Fixed Point Diffusion Models                                                                               | Bai                 | `https://openaccess.thecvf.com/content/CVPR2024/papers/Bai_Fixed_Point_Diffusion_Models_CVPR_2024_paper.pdf`                                                    | 10                | 46.                  | 4.94                   |
| 2024-01                  | Solving olympiad geometry without human demonstrations (AlphaGeometry)                                     | Trinh               | `https://www.nature.com/articles/s41586-023-06747-5.pdf`                                                                                                        | 807               | 807.                 | 6.55                   |
| 2024-02                  | Beyond A*: Planning with Transformers                                                                      | Lehnert             | `https://arxiv.org/pdf/2402.14083.pdf`                                                                                                                          | 84                | 82.                  | 4.55                   |
| 2024-04                  | VG4D: Vision-Language Model Goes 4D Video Recognition                                                      | Deng                | `https://arxiv.org/pdf/2404.11605.pdf`                                                                                                                          | 14                | 8.                   | 3.88                   |
| 2024-05                  | DAPE: Data-Adaptive Positional Encoding for Length Extrapolation                                           | Zheng               | `https://proceedings.neurips.cc/paper_files/paper/2024/file/2f050fa9f0d898e3f265d515f50ae8f9-Paper-Conference.pdf`                                              | 23                | 21.                  | 4.33                   |
| 2024-05                  | What matters when building vision-language models? (Idefics2)                                              | Laurençon           | `https://arxiv.org/pdf/2405.02246.pdf`                                                                                                                          | 385               | 383.                 | 5.50                   |
| 2024-06                  | Learning Iterative Reasoning through Energy Diffusion                                                      | Du                  | `https://arxiv.org/pdf/2406.11179.pdf`                                                                                                                          | 29                | 30.                  | 4.25                   |
| 2024-08                  | Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters                | Snell               | `https://arxiv.org/pdf/2408.03314.pdf`                                                                                                                          | 1,072             | 1,243.               | 5.98                   |
| 2024-08 (Findings ACL)   | Length Extrapolation of Causal Transformers without Position Encoding (NoPE)                               | Wang                | `https://aclanthology.org/2024.findings-acl.834.pdf`                                                                                                            | 39                | 39.                  | 4.49                   |
| 2024-09                  | H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark            | LeGris              | `https://arxiv.org/pdf/2409.01374.pdf`                                                                                                                          | 10                | 10.                  | 3.93                   |
| 2024-10 (ECCV)           | Rotary Position Embedding for Vision Transformer (RoPE-Mixed / 2D RoPE study)                              | Heo                 | `https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01584.pdf`                                                                                            | 149               | 113.                 | 5.02                   |
| 2024-10 (Findings EMNLP) | Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding                 | Zhao                | `https://aclanthology.org/2024.findings-emnlp.582.pdf`                                                                                                          | 41                | 18.                  | 4.25                   |
| 2024-11                  | ARC-Heavy / ARC-Potpourri (dataset description embedded in Cornell report)                                 | Ellis               | `https://www.cs.cornell.edu/~ellisk/documents/arc_induction_vs_transduction.pdf`                                                                                | 0                 | 0.                   | 3.19                   |
| 2024-11                  | Combining Induction and Transduction for Abstract Reasoning                                                | Li                  | `https://arxiv.org/pdf/2411.02272.pdf`                                                                                                                          | 36                | 20.                  | 4.15                   |
| 2024-11                  | Searching Latent Program Spaces                                                                            | Bonnet              | `https://arxiv.org/pdf/2411.08706.pdf`                                                                                                                          | 14                | 14.                  | 4.04                   |
| 2024-11                  | The Surprising Effectiveness of Test-Time Training for Few-Shot Learning                                   | Akyürek             | `https://ekinakyurek.github.io/papers/ttt.pdf`                                                                                                                  | 10                | 34.                  | 4.51                   |
| 2024-11                  | Towards Efficient Neurally-Guided Program Induction for ARC-AGI                                            | Ouellette           | `https://arxiv.org/pdf/2411.17708.pdf`                                                                                                                          | 6                 | 6.                   | 3.89                   |
| 2024-12 (NeurIPS)        | DAPE: Data-Adaptive Positional Encoding for Length Extrapolation                                           | Zheng               | `https://proceedings.neurips.cc/paper_files/paper/2024/file/2f050fa9f0d898e3f265d515f50ae8f9-Paper-Conference.pdf`                                              | 23                | 21.                  | 4.33                   |
| 2024-12 (NeurIPS)        | Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs                    | Ma                  | `https://proceedings.neurips.cc/paper_files/paper/2024/file/9446c291a8744a125a0bda5b18f4d5a1-Paper-Conference.pdf`                                              | 3                 | 3.                   | 3.59                   |
| 2025                     | Olympiad-level formal mathematical reasoning with large language models (AlphaProof)                       | Hubert              | `https://www.nature.com/articles/s41586-025-09833-y.pdf`                                                                                                        | 8                 | 8.                   | 3.99                   |
| 2025-02                  | VRoPE: Rotary Position Embedding for Video Large Language Models                                           | Liu                 | `https://arxiv.org/pdf/2502.11664.pdf`                                                                                                                          | 8                 | 6.                   | 3.93                   |
| 2025-04                  | SmolVLM: Redefining small and efficient multimodal models                                                  | HuggingFace         | `https://arxiv.org/pdf/2504.05299.pdf`                                                                                                                          | 112               | 111.                 | 4.46                   |
| 2025-05                  | Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models              | Wang                | `https://arxiv.org/pdf/2505.16416.pdf`                                                                                                                          | 2                 | 2.                   | 3.65                   |
| 2025-06                  | ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices | Yu                  | `https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_ComRoPE_Scalable_and_Robust_Rotary_Position_Embedding_Parameterized_by_Trainable_CVPR_2025_paper.pdf` | 2                 | 2.                   | 3.67                   |
| 2025-06                  | Hierarchical Reasoning Model (HRM)                                                                         | Wang                | `https://arxiv.org/pdf/2506.21734.pdf`                                                                                                                          | 38                | 38.                  | 5.08                   |
| 2025-09                  | Decoupling the "What" and "Where" With Polar Coordinate Positional Embeddings (PoPE)                       | Gopalakrishnan      | `https://arxiv.org/pdf/2509.10534.pdf`                                                                                                                          | 0                 | 0.                   | 2.97                   |
| 2025-10                  | Less is More: Recursive Reasoning with Tiny Networks                                                       | Jolicoeur-Martineau | `https://arxiv.org/pdf/2510.04871.pdf`                                                                                                                          | 12                | 12.                  | 4.48                   |
| 2025-11                  | DoPE: Denoising Rotary Position Embedding                                                                  | Xiong               | `https://arxiv.org/pdf/2511.09146.pdf`                                                                                                                          | 0                 | 0.                   | 2.99                   |
| 2025-11                  | Selective Rotary Position Embedding                                                                        | Movahedi            | `https://arxiv.org/pdf/2511.17388.pdf`                                                                                                                          | 0                 | 0.                   | 2.99                   |
