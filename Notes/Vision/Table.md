| Title                                                                            | Lead Author | Year / Date | PDF URL                                                                                                                                                                                                                                                                            | Citation Count | Relevance Score |
| -------------------------------------------------------------------------------- | ----------- | ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------- | --------------- |
| **End-to-End Object Detection with Transformers (DETR)**                         | Carion      | May 2020    | [https://arxiv.org/pdf/2005.12872.pdf](https://arxiv.org/pdf/2005.12872.pdf)                                                                                                                                                                                                       | ~16,000        | **9.5**         |
| **Generative Pretraining from Pixels (iGPT)**                                    | Chen        | Jun 2020    | [https://arxiv.org/pdf/2004.03441.pdf](https://arxiv.org/pdf/2004.03441.pdf)                                                                                                                                                                                                       | ~3,500         | **8.0**         |
| **An Image is Worth 16×16 Words (ViT)**                                          | Dosovitskiy | Oct 2020    | [https://arxiv.org/pdf/2010.11929.pdf](https://arxiv.org/pdf/2010.11929.pdf)                                                                                                                                                                                                       | ~35,000        | **10.0**        |
| **Taming Transformers for High-Resolution Image Synthesis**                      | Esser       | Dec 2020    | [https://openaccess.thecvf.com/content/CVPR2021/papers/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.pdf](https://openaccess.thecvf.com/content/CVPR2021/papers/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.pdf) | ~5,000         | **8.5**         |
| **Training Data-Efficient Image Transformers (DeiT)**                            | Touvron     | Jan 2021    | [https://arxiv.org/pdf/2012.12877.pdf](https://arxiv.org/pdf/2012.12877.pdf)                                                                                                                                                                                                       | ~7,000         | **9.0**         |
| **Learning Transferable Visual Models from Natural Language Supervision (CLIP)** | Radford     | Jan 2021    | [https://arxiv.org/pdf/2103.00020.pdf](https://arxiv.org/pdf/2103.00020.pdf)                                                                                                                                                                                                       | ~18,000        | **9.5**         |
| **Zero-Shot Text-to-Image Generation (DALL·E)**                                  | Ramesh      | Feb 2021    | [https://arxiv.org/pdf/2102.12092.pdf](https://arxiv.org/pdf/2102.12092.pdf)                                                                                                                                                                                                       | ~6,500         | **9.0**         |
| **Is Space-Time Attention All You Need? (TimeSformer)**                          | Bertasius   | Feb 2021    | [https://arxiv.org/pdf/2102.05095.pdf](https://arxiv.org/pdf/2102.05095.pdf)                                                                                                                                                                                                       | ~2,200         | **8.0**         |
| **Pyramid Vision Transformer (PVT)**                                             | Wang        | Feb 2021    | [https://arxiv.org/pdf/2102.12122.pdf](https://arxiv.org/pdf/2102.12122.pdf)                                                                                                                                                                                                       | ~3,000         | **8.5**         |
| **Deformable DETR**                                                              | Zhu         | Mar 2021    | [https://arxiv.org/pdf/2010.04159.pdf](https://arxiv.org/pdf/2010.04159.pdf)                                                                                                                                                                                                       | ~4,500         | **9.0**         |
| **Swin Transformer**                                                             | Liu         | Mar 2021    | [https://arxiv.org/pdf/2103.14030.pdf](https://arxiv.org/pdf/2103.14030.pdf)                                                                                                                                                                                                       | ~28,000        | **9.8**         |
| **Transformer in Transformer (TNT)**                                             | Han         | Apr 2021    | [https://arxiv.org/pdf/2103.00112.pdf](https://arxiv.org/pdf/2103.00112.pdf)                                                                                                                                                                                                       | ~900           | **7.0**         |
| **CrossViT**                                                                     | Chen        | Apr 2021    | [https://arxiv.org/pdf/2103.14899.pdf](https://arxiv.org/pdf/2103.14899.pdf)                                                                                                                                                                                                       | ~1,200         | **7.5**         |
| **CvT: Introducing Convolutions to Vision Transformers**                         | Wu          | Apr 2021    | [https://arxiv.org/pdf/2103.15808.pdf](https://arxiv.org/pdf/2103.15808.pdf)                                                                                                                                                                                                       | ~2,500         | **8.0**         |
| **SegFormer**                                                                    | Xie         | Sep 2021    | [https://arxiv.org/pdf/2105.15203.pdf](https://arxiv.org/pdf/2105.15203.pdf)                                                                                                                                                                                                       | ~2,800         | **8.5**         |
| **BEiT: BERT Pre-Training of Image Transformers**                                | Bao         | Jun 2021    | [https://arxiv.org/pdf/2106.08254.pdf](https://arxiv.org/pdf/2106.08254.pdf)                                                                                                                                                                                                       | ~4,000         | **9.0**         |
| **Masked Autoencoders Are Scalable Vision Learners (MAE)**                       | He          | Nov 2021    | [https://arxiv.org/pdf/2111.06377.pdf](https://arxiv.org/pdf/2111.06377.pdf)                                                                                                                                                                                                       | ~8,500         | **9.5**         |
| **CoAtNet: Marrying Convolution and Attention**                                  | Dai         | Oct 2021    | [https://arxiv.org/pdf/2106.04803.pdf](https://arxiv.org/pdf/2106.04803.pdf)                                                                                                                                                                                                       | ~1,800         | **8.5**         |
| **Swin Transformer V2**                                                          | Liu         | Jan 2022    | [https://arxiv.org/pdf/2111.09883.pdf](https://arxiv.org/pdf/2111.09883.pdf)                                                                                                                                                                                                       | ~3,000         | **8.5**         |
| **CSWin Transformer**                                                            | Dong        | Feb 2022    | [https://arxiv.org/pdf/2107.00652.pdf](https://arxiv.org/pdf/2107.00652.pdf)                                                                                                                                                                                                       | ~1,600         | **8.0**         |
| **MaxViT**                                                                       | Tu          | Jul 2022    | [https://arxiv.org/pdf/2204.01697.pdf](https://arxiv.org/pdf/2204.01697.pdf)                                                                                                                                                                                                       | ~1,200         | **8.0**         |
| **Segment Anything (SAM)**                                                       | Kirillov    | Apr 2023    | [https://arxiv.org/pdf/2304.02643.pdf](https://arxiv.org/pdf/2304.02643.pdf)                                                                                                                                                                                                       | ~9,000         | **9.5**         |
