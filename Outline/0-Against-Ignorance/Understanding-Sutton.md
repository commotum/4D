While large amounts of knowledge is a great strength of AI systems, it is also a great weakness. The problem is that as knowledge bases grow they become more brittle and difficult to maintain. There arise inconsistencies in the terminology used by different people or at different times. The more diverse the knowledge the greater are the opportunities for confusions. Errors are inevitably present, if only because of typos in data entry. When an error becomes apparent, the problem can only be fixed by a human who is expert in the structure and terminology of the knowledge base. This is the root difficulty: the accuracy of the knowledge can ultimately only be verified and safely maintained by a person intimately familiar with most of the knowledge and its representation. This puts an upper bound on the size of the knowledge base. **As long as people are the ultimate guarantors—nay, definers—of truth, then the machine cannot become much smarter than its human handlers.** Verifying knowledge by consistency with human knowledge is ultimately, inevitably, a dead end.

All goals and purposes can be well thought of as the maximization of the expected value of the cumulative sum of a single externally received number (reward).

All action is taken at the shortest possible time scale, by a reactive, moment-by-moment policy function mapping from state to action. Anything higher or at longer time scales is for thinking about action, not for taking it. "All behavior is reactive"

State representations, like all knowledge, should be tied to experience as much as possible. Thus, the Bayesian and POMDP conceptions of state estimation are mistaken.

"He’s pushing back on the idea that “the right state” is something you compute by having a correct probabilistic model of the world. In practice, you often don’t have that model—and in RL you may prefer to learn a representation directly from experience that’s good for prediction/control, rather than maintaining a full Bayes belief over hidden states."

Any prediction problem can be cast in the supervised-learning paradigm by raking the first item to be the data based on which a prediction must be made. and the second item to be the actual outcome, what the prediction should have been. For example to predict Saturday's weather. one can form a pair from the measurements taken on Monday and the actual observed weather on Saturday. another pair from the measurements taken on Tuesday and Saturday's weather, and so on. Although this pairwise approach ignores the sequential structure of the problem, it is easy to understand and analyze and it has been widely used. In this paper, we refer to this as the supervised-learning approach to prediction learning, and we refer to learning methods that take this approach as supervised-learning methods. We argue that such methods are inadequate, and that TD methods are far preferable.

To clarify this claim, we distinguish two kinds of prediction-learning problems. In single-step prediction problems, all information about the correctness of each prediction is revealed at once. In multi-step prediction problems, correctness is not revealed until more than one step after the prediction is made, but partial information relevant to its correctness is revealed at each step. For example, the weather prediction problem mentioned above is a multi-step prediction problem because inconclusive evidence relevant to the correctness of Monday's prediction becomes available in the form of new observations on Tuesday, Wednesday, Thursday and Friday. On the other hand, if each day's weather were to be predicted on the basis of the previous day's observations that is, on Monday predict Tuesday's weather, on Tuesday predict Wednesday's weather, etc. - one would have a single-step prediction problem, assuming no further observations were made between the time of each day's prediction and its confirmation or refutation on the following day.

In this paper, we will be concerned only with multi-step prediction problems. In single-step problems, data naturally comes in observation-outcome pairs; these problems are ideally suited to the pairwise supervised-learning approach. Temporal-difference methods cannot be distinguished from supervised-learning methods in this case; thus the former improve over conventional methods only on multi-step problems. However, we argue that these predominate in realworld applications. For example, predictions about next year's economic performance are not confirmed or disconfirmed all at once, but rather bit by bit as the economic situation is observed through the year. The likely outcome of elections is updated with each new poll, and the likely outcome of a chess game is updated with each move. When a baseball batter predicts whether a pitch will be a strike, he updates his prediction continuously during the ball's flight.

In fact, many problems that are classically cast as single-step prediction problems are more naturally viewed as multi-step problems. Perceptual learning problems, such as vision or speech recognition, are classically treated as supervised learning, using a training set of isolated, correctly-classified input patterns. When humans hear or see things, on the other hand, they receive a stream of input over time and constantly update their hypotheses about what they are seeing or hearing. People are faced not with a single-step problem of unrelated pattern class pairs, but rather with a series of related patterns, all providing information about the same classification. To disregard this structure seems improvident.

For knowledge to be clear, the experiment and the measurement corresponding to the question must be specified unambiguously and in detail. We state this viewpoint as the explicit prediction manifesto:

> Every prediction is a question and an answer.
> Both the question and the answer must be explicit in the sense of being accessible to the AI agent, i.e., of being machine readable, interpretable, and usable.

The grand challenge of grounding knowledge in experience:

> To represent human-level world knowledge solely in terms of experience, that is, in terms of observations, actions, and time steps, without reference to any other concepts or entities unless they are themselves represented in terms of experience.
