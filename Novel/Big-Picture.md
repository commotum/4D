The continual learning problem can be widely viewed as one of two problems:


NEED SUTTON INTERVIEW TRANSCRIPTS.




1. How to train on new data without catastrophically forgetting
2. Stateful memory so not each chat is starting over

Continual learning side: AGI needs systems that can keep learning after deployment so they don’t repeat the same failures forever and can “unstick” themselves over time.

Stateful working memory side: Even perfect continual learning won’t stop agent drift/amnesia unless the system has stateful inference/working memory so intent and latent context survive across steps instead of being re-inferred from scratch every turn.

1. Original catastrophic forgetting problem has been solved, through data mixture and large scale training.
 "quanta of learning" theory is largely accurate so then it becomes a problem of finding out what skills are valuable and what order learning should occur in. King of the hill solves this.

2. Working memory with VAE for hierarchical structure solves 2

---

3. ok, but how do we extend to more domains, VITs haven't really been all that successful yet

MonSTER boom.

---

VOCAb

